{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(\"..\")\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from interactions import ExactInteractions\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exact layer \n",
    "\n",
    "Creates a interaction matrix S were each entry $i$ and $j$ are defined by:\n",
    "\n",
    "$s_{ij}=\\begin{cases}1 & q_i = d_i\\\\0 & otherwise\\end{cases}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 10)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 12)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "exact_interactions (ExactIntera (None, 10, 12)       0           input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "   \n",
    "K.clear_session()\n",
    "\n",
    "input_query = tf.keras.layers.Input((10,), dtype=\"int32\")\n",
    "input_sentence = tf.keras.layers.Input((12,), dtype=\"int32\")\n",
    "\n",
    "exact_interaction = ExactInteractions()\n",
    "\n",
    "_out = exact_interaction([input_query, input_sentence])\n",
    "\n",
    "model = tf.keras.models.Model(inputs=[input_query, input_sentence], outputs=_out)\n",
    "model.summary()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = np.random.randint(1,4,(1, 10))\n",
    "document = np.random.randint(1,4,(1, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1.],\n",
       "        [0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = model.predict([query, document])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add padding\n",
    "query[:,5:] = np.zeros(5,)\n",
    "document[:,6:] = np.zeros(6,)\n",
    "y = model.predict([query, document])\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exact Layer with term importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "exact_interactions (ExactIntera (None, 8, 4, 3)      0           input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "   \n",
    "K.clear_session()\n",
    "\n",
    "input_query = tf.keras.layers.Input((8,), dtype=\"int32\")\n",
    "input_sentence = tf.keras.layers.Input((4,), dtype=\"int32\")\n",
    "\n",
    "input_query_t_importance = tf.keras.layers.Input((8,), dtype=\"float32\")\n",
    "input_sentence_t_importance = tf.keras.layers.Input((4,), dtype=\"float32\")\n",
    "\n",
    "_inputs = [input_query, input_sentence, input_query_t_importance, input_sentence_t_importance]\n",
    "\n",
    "exact_interaction = ExactInteractions()\n",
    "\n",
    "_out = exact_interaction(_inputs)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=_inputs, outputs=_out)\n",
    "model.summary()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = np.random.randint(1,10,(1, 8))\n",
    "sentence = np.random.randint(1,10,(1, 4))\n",
    "\n",
    "query_importance = np.random.random((1, 8))\n",
    "sentence_importance = np.random.random((1, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 1.]\n",
      " [1. 0. 0. 0.]]\n",
      "[[0.0992586  0.0992586  0.0992586  0.0992586 ]\n",
      " [0.8366827  0.8366827  0.8366827  0.8366827 ]\n",
      " [0.552322   0.552322   0.552322   0.552322  ]\n",
      " [0.18749177 0.18749177 0.18749177 0.18749177]\n",
      " [0.9671816  0.9671816  0.9671816  0.9671816 ]\n",
      " [0.52295625 0.52295625 0.52295625 0.52295625]\n",
      " [0.84259874 0.84259874 0.84259874 0.84259874]\n",
      " [0.20079795 0.20079795 0.20079795 0.20079795]]\n",
      "[[0.8589076  0.90894186 0.2348578  0.8571401 ]\n",
      " [0.8589076  0.90894186 0.2348578  0.8571401 ]\n",
      " [0.8589076  0.90894186 0.2348578  0.8571401 ]\n",
      " [0.8589076  0.90894186 0.2348578  0.8571401 ]\n",
      " [0.8589076  0.90894186 0.2348578  0.8571401 ]\n",
      " [0.8589076  0.90894186 0.2348578  0.8571401 ]\n",
      " [0.8589076  0.90894186 0.2348578  0.8571401 ]\n",
      " [0.8589076  0.90894186 0.2348578  0.8571401 ]]\n"
     ]
    }
   ],
   "source": [
    "y = model.predict([query, sentence, query_importance, sentence_importance])\n",
    "print(y[0,:,:,0])\n",
    "print(y[0,:,:,1])\n",
    "print(y[0,:,:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "[[0.0992586  0.0992586  0.         0.        ]\n",
      " [0.8366827  0.8366827  0.         0.        ]\n",
      " [0.552322   0.552322   0.         0.        ]\n",
      " [0.18749177 0.18749177 0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]]\n",
      "[[0.8589076  0.90894186 0.         0.        ]\n",
      " [0.8589076  0.90894186 0.         0.        ]\n",
      " [0.8589076  0.90894186 0.         0.        ]\n",
      " [0.8589076  0.90894186 0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "query[:,4:] = np.zeros(4,)\n",
    "sentence[:,2:] = np.zeros(2,)\n",
    "query_importance[:,4:] = np.zeros(4,)\n",
    "sentence_importance[:,2:] = np.zeros(2,)\n",
    "\n",
    "y = model.predict([query, sentence, query_importance, sentence_importance])\n",
    "print(y[0,:,:,0])\n",
    "print(y[0,:,:,1])\n",
    "print(y[0,:,:,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interactions import SemanticInteractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG created tokenizer disk4_5_RegexTokenizer\n",
      "False False\n",
      "[LOAD FROM CACHE] Load embedding matrix from /backup/IR/embedding_wiki_disk4_5_RegexTokenizer\n"
     ]
    }
   ],
   "source": [
    "from nir.embeddings import FastText\n",
    "from nir.tokenizers import Regex\n",
    "\n",
    "cache_folder = \"/backup/IR\"\n",
    "prefix_name = \"disk4_5\"\n",
    "\n",
    "# load tokenizer\n",
    "tk = Regex.load_from_json(cache_folder=cache_folder, prefix_name=prefix_name)\n",
    "\n",
    "# load embedding matrix\n",
    "ft = FastText.maybe_load(cache_folder = cache_folder,\n",
    "                         prefix_name = prefix_name,\n",
    "                         path = \"/backup/pre-trained_embeddings/fasttext/wiki.en.bin\",\n",
    "                         tokenizer = tk)\n",
    "\n",
    "emb_matrix = ft.embedding_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EMBEDDING MATRIX SHAPE] (228107, 300)\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "semantic_interactions (Semantic (None, 8, 4, 3)      600         input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 600\n",
      "Trainable params: 600\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "K.clear_session()\n",
    "\n",
    "input_query = tf.keras.layers.Input((8,), dtype=\"int32\")\n",
    "input_sentence = tf.keras.layers.Input((4,), dtype=\"int32\")\n",
    "\n",
    "semantic_interaction = SemanticInteractions(emb_matrix)\n",
    "\n",
    "_out = semantic_interaction([input_query, input_sentence])\n",
    "\n",
    "model = tf.keras.models.Model(inputs=[input_query, input_sentence], outputs=_out)\n",
    "model.summary()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = np.random.randint(1,100000,(1, 8))\n",
    "document = np.random.randint(1,100000,(1, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.12195162 0.3060188  0.07169754 0.22878772]\n",
      " [0.15432015 0.3396184  0.05373091 0.31086975]\n",
      " [0.15998912 0.22292125 0.09267265 0.23756436]\n",
      " [0.15174542 0.22771084 0.14356448 0.10540374]\n",
      " [0.15426344 0.08843064 0.17623109 0.20108868]\n",
      " [0.20685682 0.257168   0.08523287 0.24533218]\n",
      " [0.12268002 0.24191794 0.05046202 0.19189438]\n",
      " [0.22307785 0.08852232 0.10685393 0.19338246]]\n",
      "[[-9.8678552e-02 -9.8678552e-02 -9.8678552e-02 -9.8678552e-02]\n",
      " [ 2.5561264e-02  2.5561264e-02  2.5561264e-02  2.5561264e-02]\n",
      " [ 4.4735774e-02  4.4735774e-02  4.4735774e-02  4.4735774e-02]\n",
      " [-9.1937594e-03 -9.1937594e-03 -9.1937594e-03 -9.1937594e-03]\n",
      " [-3.7848368e-02 -3.7848368e-02 -3.7848368e-02 -3.7848368e-02]\n",
      " [-3.4315750e-02 -3.4315750e-02 -3.4315750e-02 -3.4315750e-02]\n",
      " [ 7.3319417e-05  7.3319417e-05  7.3319417e-05  7.3319417e-05]\n",
      " [ 1.7905701e-02  1.7905701e-02  1.7905701e-02  1.7905701e-02]]\n",
      "[[-6.1611237e-05  2.0398768e-02  4.9427930e-02 -8.2756080e-02]\n",
      " [-6.1611237e-05  2.0398768e-02  4.9427930e-02 -8.2756080e-02]\n",
      " [-6.1611237e-05  2.0398768e-02  4.9427930e-02 -8.2756080e-02]\n",
      " [-6.1611237e-05  2.0398768e-02  4.9427930e-02 -8.2756080e-02]\n",
      " [-6.1611237e-05  2.0398768e-02  4.9427930e-02 -8.2756080e-02]\n",
      " [-6.1611237e-05  2.0398768e-02  4.9427930e-02 -8.2756080e-02]\n",
      " [-6.1611237e-05  2.0398768e-02  4.9427930e-02 -8.2756080e-02]\n",
      " [-6.1611237e-05  2.0398768e-02  4.9427930e-02 -8.2756080e-02]]\n"
     ]
    }
   ],
   "source": [
    "y = model.predict([query, document])\n",
    "print(y[0,:,:,0])\n",
    "print(y[0,:,:,1])\n",
    "print(y[0,:,:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.12195162  0.3060188  -0.         -0.        ]\n",
      " [ 0.15432015  0.3396184  -0.         -0.        ]\n",
      " [ 0.15998912  0.22292125 -0.         -0.        ]\n",
      " [ 0.15174542  0.22771084  0.          0.        ]\n",
      " [-0.         -0.          0.          0.        ]\n",
      " [-0.         -0.          0.          0.        ]\n",
      " [-0.         -0.          0.          0.        ]\n",
      " [-0.         -0.          0.          0.        ]]\n",
      "[[-0.09867855 -0.09867855 -0.         -0.        ]\n",
      " [ 0.02556126  0.02556126  0.          0.        ]\n",
      " [ 0.04473577  0.04473577  0.          0.        ]\n",
      " [-0.00919376 -0.00919376 -0.         -0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "[[-6.1611237e-05  2.0398768e-02 -0.0000000e+00 -0.0000000e+00]\n",
      " [-6.1611237e-05  2.0398768e-02 -0.0000000e+00 -0.0000000e+00]\n",
      " [-6.1611237e-05  2.0398768e-02 -0.0000000e+00 -0.0000000e+00]\n",
      " [-6.1611237e-05  2.0398768e-02 -0.0000000e+00 -0.0000000e+00]\n",
      " [-0.0000000e+00  0.0000000e+00 -0.0000000e+00 -0.0000000e+00]\n",
      " [-0.0000000e+00  0.0000000e+00 -0.0000000e+00 -0.0000000e+00]\n",
      " [-0.0000000e+00  0.0000000e+00 -0.0000000e+00 -0.0000000e+00]\n",
      " [-0.0000000e+00  0.0000000e+00 -0.0000000e+00 -0.0000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# add padding\n",
    "query[:,4:] = np.zeros(4,)\n",
    "document[:,2:] = np.zeros(2,)\n",
    "y = model.predict([query, document])\n",
    "print(y[0,:,:,0])\n",
    "print(y[0,:,:,1])\n",
    "print(y[0,:,:,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context semantic layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interactions import MatrixInteractionMasking\n",
    "\n",
    "class ContextedSemanticInteractions(MatrixInteractionMasking):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 context_embedding_layer = None,\n",
    "                 cls_token_id = None,\n",
    "                 sep_token_id = None,\n",
    "                 pad_token_id = None,\n",
    "                 context_embedding_dim = None, # used to compute the term importance of each query and sentence token\n",
    "                 initializer='glorot_uniform',\n",
    "                 regularizer=None,\n",
    "                 **kwargs):\n",
    "        \n",
    "        super(ContextedSemanticInteractions, self).__init__(**kwargs)\n",
    "\n",
    "        self.context_embedding_layer = context_embedding_layer\n",
    "        self.context_embedding_dim = context_embedding_dim\n",
    "        self.cls_token_id = cls_token_id\n",
    "        self.sep_token_id = sep_token_id\n",
    "        self.pad_token_id = pad_token_id\n",
    "        self.initializer = initializer\n",
    "        self.regularizer = regularizer\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        # add some weight that will learn term importance projection of the query and sentence embeddings\n",
    "        if self.context_embedding_dim is not None:\n",
    "            self.query_w = self.add_weight(name=\"query_w\",\n",
    "                                           shape=(self.context_embedding_dim, 1),\n",
    "                                           initializer=self.initializer,\n",
    "                                           regularizer=self.regularizer,\n",
    "                                           trainable=True)\n",
    "            \n",
    "            self.sentence_w = self.add_weight(name=\"sentence_w\",\n",
    "                                              shape=(self.context_embedding_dim, 1),\n",
    "                                              initializer=self.initializer,\n",
    "                                              regularizer=self.regularizer,\n",
    "                                              trainable=True)\n",
    "        \n",
    "        super(ContextedSemanticInteractions, self).build(input_shape)\n",
    "        \n",
    "    def _produce_context_embeddings(self, query_vector, sentence_vector):\n",
    "        # assume transformer layer follows a BERT architecture\n",
    "        assert(self.cls_token_id is not None and self.sep_token_id is not None and self.pad_token_id is not None)\n",
    "        \n",
    "        batch_dim = tf.shape(query_vector)[0]\n",
    "        \n",
    "        cls_input = K.expand_dims(tf.ones((batch_dim,))*tf.constant(self.cls_token_id))\n",
    "        sep_input = K.expand_dims(tf.ones((batch_dim,))*tf.constant(self.sep_token_id))\n",
    "        \n",
    "        _input = K.concatenate([cls_input, query_vector, sep_input, sentence_vector, sep_input])\n",
    "\n",
    "        _out = self.context_embedding_layer(_input)\n",
    "        \n",
    "        context_query = _out[:,1:self.query_max_elements+1,:]\n",
    "        context_sentence = _out[:,self.query_max_elements+2:self.query_max_elements+2+self.setence_max_elements,:]\n",
    "        \n",
    "        return context_query, context_sentence\n",
    "        \n",
    "    def call(self, x, mask=None):\n",
    "        \"\"\"\n",
    "        x[0] - padded query tokens id's\n",
    "        x[1] - padded sentence tokens id's\n",
    "        \n",
    "        or \n",
    "        \n",
    "        For this setting the mask is needed\n",
    "        x[0] - padded query context embeddings\n",
    "        x[1] - padded sentence context embeddings\n",
    "        \n",
    "        or\n",
    "        \n",
    "        For this setting the mask is needed\n",
    "        x    - pre-computed similarity matrix, dims (B,Q,D)\n",
    "        \"\"\"\n",
    "        \n",
    "        if mask is None:\n",
    "            mask = self.compute_mask(x)\n",
    "        \n",
    "        if self.context_embedding_layer is not None:\n",
    "            query_context_embeddings, sentence_context_embeddings = self._produce_context_embeddings(x[0], x[1]) \n",
    "        else:\n",
    "            query_context_embeddings, sentence_context_embeddings = (x[0],x[1])\n",
    "            \n",
    "        if len(x)==2:\n",
    "            interaction_matrix = tf.einsum(\"bqe,bde->bqd\", query_context_embeddings, sentence_context_embeddings) * mask\n",
    "        else:\n",
    "            interaction_matrix = x * mask\n",
    "        \n",
    "        if self.context_embedding_dim is not None:\n",
    "            mask = K.expand_dims(mask) # TODO check the rank of the tensor before expand??\n",
    "            \n",
    "            query_context_embeddings = K.dot(query_context_embeddings, self.query_w)\n",
    "            sentence_context_embeddings = K.dot(sentence_context_embeddings, self.sentence_w)\n",
    "            \n",
    "            query_projection_matrix, sentence_projection_matrix = self._query_sentence_vector_to_matrices(query_context_embeddings, sentence_context_embeddings) \n",
    "            \n",
    "            query_projection_matrix = query_projection_matrix * mask\n",
    "            sentence_projection_matrix = sentence_projection_matrix * mask\n",
    "            \n",
    "            interaction_matrix = K.expand_dims(interaction_matrix)\n",
    "            interaction_matrix = K.concatenate([interaction_matrix, query_projection_matrix, sentence_projection_matrix])\n",
    "        \n",
    "        return interaction_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"contexted_semantic_interactions/mul:0\", shape=(None,), dtype=float32)\n",
      "Tensor(\"contexted_semantic_interactions/mul_1:0\", shape=(None,), dtype=float32)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in converted code:\n\n    <ipython-input-5-5f728536f853>:75 call  *\n        query_context_embeddings, sentence_context_embeddings = self._produce_context_embeddings(x[0], x[1])\n\n    TypeError: 'NoneType' object is not iterable\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-36d81fe01789>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m                                  pad_token_id = 0.,)\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0m_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msemantic_interaction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_sentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_sentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Spatial-RNN-GRU/tf2/lib/python3.5/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    840\u001b[0m                     not base_layer_utils.is_in_eager_or_tf_function()):\n\u001b[1;32m    841\u001b[0m                   \u001b[0;32mwith\u001b[0m \u001b[0mauto_control_deps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAutomaticControlDependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0macd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 842\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    843\u001b[0m                     \u001b[0;31m# Wrap Tensors in `outputs` in `tf.identity` to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m                     \u001b[0;31m# circular dependencies.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Spatial-RNN-GRU/tf2/lib/python3.5/site-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: in converted code:\n\n    <ipython-input-5-5f728536f853>:75 call  *\n        query_context_embeddings, sentence_context_embeddings = self._produce_context_embeddings(x[0], x[1])\n\n    TypeError: 'NoneType' object is not iterable\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "input_query = tf.keras.layers.Input((8,), dtype=\"int32\")\n",
    "input_sentence = tf.keras.layers.Input((4,), dtype=\"int32\")\n",
    "\n",
    "semantic_interaction = ContextedSemanticInteractions(\n",
    "                                 context_embedding_layer = [],\n",
    "                                 cls_token_id = 2.,\n",
    "                                 sep_token_id = 3.,\n",
    "                                 pad_token_id = 0.,)\n",
    "\n",
    "_out = semantic_interaction([input_query, input_sentence])\n",
    "\n",
    "model = tf.keras.models.Model(inputs=[input_query, input_sentence], outputs=_out)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow2Wnir",
   "language": "python",
   "name": "tensor2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

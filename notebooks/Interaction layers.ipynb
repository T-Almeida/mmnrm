{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(\"..\")\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from interactions import ExactInteractions\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exact layer \n",
    "\n",
    "Creates a interaction matrix S were each entry $i$ and $j$ are defined by:\n",
    "\n",
    "$s_{ij}=\\begin{cases}1 & q_i = d_i\\\\0 & otherwise\\end{cases}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 10)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 12)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "exact_interactions (ExactIntera (None, 10, 12)       0           input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "   \n",
    "K.clear_session()\n",
    "\n",
    "input_query = tf.keras.layers.Input((10,), dtype=\"int32\")\n",
    "input_sentence = tf.keras.layers.Input((12,), dtype=\"int32\")\n",
    "\n",
    "exact_interaction = ExactInteractions()\n",
    "\n",
    "_out = exact_interaction([input_query, input_sentence])\n",
    "\n",
    "model = tf.keras.models.Model(inputs=[input_query, input_sentence], outputs=_out)\n",
    "model.summary()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = np.random.randint(1,4,(1, 10))\n",
    "document = np.random.randint(1,4,(1, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.],\n",
       "        [1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1.],\n",
       "        [0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = model.predict([query, document])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add padding\n",
    "query[:,5:] = np.zeros(5,)\n",
    "document[:,6:] = np.zeros(6,)\n",
    "y = model.predict([query, document])\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exact Layer with term importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "exact_interactions (ExactIntera (None, 8, 4, 3)      0           input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "   \n",
    "K.clear_session()\n",
    "\n",
    "input_query = tf.keras.layers.Input((8,), dtype=\"int32\")\n",
    "input_sentence = tf.keras.layers.Input((4,), dtype=\"int32\")\n",
    "\n",
    "input_query_t_importance = tf.keras.layers.Input((8,), dtype=\"float32\")\n",
    "input_sentence_t_importance = tf.keras.layers.Input((4,), dtype=\"float32\")\n",
    "\n",
    "_inputs = [input_query, input_sentence, input_query_t_importance, input_sentence_t_importance]\n",
    "\n",
    "exact_interaction = ExactInteractions()\n",
    "\n",
    "_out = exact_interaction(_inputs)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=_inputs, outputs=_out)\n",
    "model.summary()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = np.random.randint(1,10,(1, 8))\n",
    "sentence = np.random.randint(1,10,(1, 4))\n",
    "\n",
    "query_importance = np.random.random((1, 8))\n",
    "sentence_importance = np.random.random((1, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 1.]\n",
      " [1. 0. 0. 0.]]\n",
      "[[0.0992586  0.0992586  0.0992586  0.0992586 ]\n",
      " [0.8366827  0.8366827  0.8366827  0.8366827 ]\n",
      " [0.552322   0.552322   0.552322   0.552322  ]\n",
      " [0.18749177 0.18749177 0.18749177 0.18749177]\n",
      " [0.9671816  0.9671816  0.9671816  0.9671816 ]\n",
      " [0.52295625 0.52295625 0.52295625 0.52295625]\n",
      " [0.84259874 0.84259874 0.84259874 0.84259874]\n",
      " [0.20079795 0.20079795 0.20079795 0.20079795]]\n",
      "[[0.8589076  0.90894186 0.2348578  0.8571401 ]\n",
      " [0.8589076  0.90894186 0.2348578  0.8571401 ]\n",
      " [0.8589076  0.90894186 0.2348578  0.8571401 ]\n",
      " [0.8589076  0.90894186 0.2348578  0.8571401 ]\n",
      " [0.8589076  0.90894186 0.2348578  0.8571401 ]\n",
      " [0.8589076  0.90894186 0.2348578  0.8571401 ]\n",
      " [0.8589076  0.90894186 0.2348578  0.8571401 ]\n",
      " [0.8589076  0.90894186 0.2348578  0.8571401 ]]\n"
     ]
    }
   ],
   "source": [
    "y = model.predict([query, sentence, query_importance, sentence_importance])\n",
    "print(y[0,:,:,0])\n",
    "print(y[0,:,:,1])\n",
    "print(y[0,:,:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "[[0.0992586  0.0992586  0.         0.        ]\n",
      " [0.8366827  0.8366827  0.         0.        ]\n",
      " [0.552322   0.552322   0.         0.        ]\n",
      " [0.18749177 0.18749177 0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]]\n",
      "[[0.8589076  0.90894186 0.         0.        ]\n",
      " [0.8589076  0.90894186 0.         0.        ]\n",
      " [0.8589076  0.90894186 0.         0.        ]\n",
      " [0.8589076  0.90894186 0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "query[:,4:] = np.zeros(4,)\n",
    "sentence[:,2:] = np.zeros(2,)\n",
    "query_importance[:,4:] = np.zeros(4,)\n",
    "sentence_importance[:,2:] = np.zeros(2,)\n",
    "\n",
    "y = model.predict([query, sentence, query_importance, sentence_importance])\n",
    "print(y[0,:,:,0])\n",
    "print(y[0,:,:,1])\n",
    "print(y[0,:,:,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interactions import SemanticInteractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG created tokenizer disk4_5_RegexTokenizer\n",
      "False False\n",
      "[LOAD FROM CACHE] Load embedding matrix from /backup/IR/embedding_wiki_disk4_5_RegexTokenizer\n"
     ]
    }
   ],
   "source": [
    "from nir.embeddings import FastText\n",
    "from nir.tokenizers import Regex\n",
    "\n",
    "cache_folder = \"/backup/IR\"\n",
    "prefix_name = \"disk4_5\"\n",
    "\n",
    "# load tokenizer\n",
    "tk = Regex.load_from_json(cache_folder=cache_folder, prefix_name=prefix_name)\n",
    "\n",
    "# load embedding matrix\n",
    "ft = FastText.maybe_load(cache_folder = cache_folder,\n",
    "                         prefix_name = prefix_name,\n",
    "                         path = \"/backup/pre-trained_embeddings/fasttext/wiki.en.bin\",\n",
    "                         tokenizer = tk)\n",
    "\n",
    "emb_matrix = ft.embedding_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EMBEDDING MATRIX SHAPE] (228107, 300)\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "semantic_interactions (Semantic (None, 8, 4, 3)      600         input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 600\n",
      "Trainable params: 600\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "K.clear_session()\n",
    "\n",
    "input_query = tf.keras.layers.Input((8,), dtype=\"int32\")\n",
    "input_sentence = tf.keras.layers.Input((4,), dtype=\"int32\")\n",
    "\n",
    "semantic_interaction = SemanticInteractions(emb_matrix)\n",
    "\n",
    "_out = semantic_interaction([input_query, input_sentence])\n",
    "\n",
    "model = tf.keras.models.Model(inputs=[input_query, input_sentence], outputs=_out)\n",
    "model.summary()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = np.random.randint(1,100000,(1, 8))\n",
    "document = np.random.randint(1,100000,(1, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.12195162 0.3060188  0.07169754 0.22878772]\n",
      " [0.15432015 0.3396184  0.05373091 0.31086975]\n",
      " [0.15998912 0.22292125 0.09267265 0.23756436]\n",
      " [0.15174542 0.22771084 0.14356448 0.10540374]\n",
      " [0.15426344 0.08843064 0.17623109 0.20108868]\n",
      " [0.20685682 0.257168   0.08523287 0.24533218]\n",
      " [0.12268002 0.24191794 0.05046202 0.19189438]\n",
      " [0.22307785 0.08852232 0.10685393 0.19338246]]\n",
      "[[-9.8678552e-02 -9.8678552e-02 -9.8678552e-02 -9.8678552e-02]\n",
      " [ 2.5561264e-02  2.5561264e-02  2.5561264e-02  2.5561264e-02]\n",
      " [ 4.4735774e-02  4.4735774e-02  4.4735774e-02  4.4735774e-02]\n",
      " [-9.1937594e-03 -9.1937594e-03 -9.1937594e-03 -9.1937594e-03]\n",
      " [-3.7848368e-02 -3.7848368e-02 -3.7848368e-02 -3.7848368e-02]\n",
      " [-3.4315750e-02 -3.4315750e-02 -3.4315750e-02 -3.4315750e-02]\n",
      " [ 7.3319417e-05  7.3319417e-05  7.3319417e-05  7.3319417e-05]\n",
      " [ 1.7905701e-02  1.7905701e-02  1.7905701e-02  1.7905701e-02]]\n",
      "[[-6.1611237e-05  2.0398768e-02  4.9427930e-02 -8.2756080e-02]\n",
      " [-6.1611237e-05  2.0398768e-02  4.9427930e-02 -8.2756080e-02]\n",
      " [-6.1611237e-05  2.0398768e-02  4.9427930e-02 -8.2756080e-02]\n",
      " [-6.1611237e-05  2.0398768e-02  4.9427930e-02 -8.2756080e-02]\n",
      " [-6.1611237e-05  2.0398768e-02  4.9427930e-02 -8.2756080e-02]\n",
      " [-6.1611237e-05  2.0398768e-02  4.9427930e-02 -8.2756080e-02]\n",
      " [-6.1611237e-05  2.0398768e-02  4.9427930e-02 -8.2756080e-02]\n",
      " [-6.1611237e-05  2.0398768e-02  4.9427930e-02 -8.2756080e-02]]\n"
     ]
    }
   ],
   "source": [
    "y = model.predict([query, document])\n",
    "print(y[0,:,:,0])\n",
    "print(y[0,:,:,1])\n",
    "print(y[0,:,:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.12195162  0.3060188  -0.         -0.        ]\n",
      " [ 0.15432015  0.3396184  -0.         -0.        ]\n",
      " [ 0.15998912  0.22292125 -0.         -0.        ]\n",
      " [ 0.15174542  0.22771084  0.          0.        ]\n",
      " [-0.         -0.          0.          0.        ]\n",
      " [-0.         -0.          0.          0.        ]\n",
      " [-0.         -0.          0.          0.        ]\n",
      " [-0.         -0.          0.          0.        ]]\n",
      "[[-0.09867855 -0.09867855 -0.         -0.        ]\n",
      " [ 0.02556126  0.02556126  0.          0.        ]\n",
      " [ 0.04473577  0.04473577  0.          0.        ]\n",
      " [-0.00919376 -0.00919376 -0.         -0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "[[-6.1611237e-05  2.0398768e-02 -0.0000000e+00 -0.0000000e+00]\n",
      " [-6.1611237e-05  2.0398768e-02 -0.0000000e+00 -0.0000000e+00]\n",
      " [-6.1611237e-05  2.0398768e-02 -0.0000000e+00 -0.0000000e+00]\n",
      " [-6.1611237e-05  2.0398768e-02 -0.0000000e+00 -0.0000000e+00]\n",
      " [-0.0000000e+00  0.0000000e+00 -0.0000000e+00 -0.0000000e+00]\n",
      " [-0.0000000e+00  0.0000000e+00 -0.0000000e+00 -0.0000000e+00]\n",
      " [-0.0000000e+00  0.0000000e+00 -0.0000000e+00 -0.0000000e+00]\n",
      " [-0.0000000e+00  0.0000000e+00 -0.0000000e+00 -0.0000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# add padding\n",
    "query[:,4:] = np.zeros(4,)\n",
    "document[:,2:] = np.zeros(2,)\n",
    "y = model.predict([query, document])\n",
    "print(y[0,:,:,0])\n",
    "print(y[0,:,:,1])\n",
    "print(y[0,:,:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow2Wnir",
   "language": "python",
   "name": "tensor2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

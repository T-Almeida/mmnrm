{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(\"..\")\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from interactions import ExactInteractions\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exact layer \n",
    "\n",
    "Creates a interaction matrix S were each entry $i$ and $j$ are defined by:\n",
    "\n",
    "$s_{ij}=\\begin{cases}1 & q_i = d_i\\\\0 & otherwise\\end{cases}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 10)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 12)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "exact_interactions (ExactIntera (None, 10, 12)       0           input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "   \n",
    "K.clear_session()\n",
    "\n",
    "input_query = tf.keras.layers.Input((10,), dtype=\"int32\")\n",
    "input_sentence = tf.keras.layers.Input((12,), dtype=\"int32\")\n",
    "\n",
    "exact_interaction = ExactInteractions()\n",
    "\n",
    "_out = exact_interaction([input_query, input_sentence])\n",
    "\n",
    "model = tf.keras.models.Model(inputs=[input_query, input_sentence], outputs=_out)\n",
    "model.summary()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = np.random.randint(0,4,(1, 10))\n",
    "document = np.random.randint(0,4,(1, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0.],\n",
       "        [0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = model.predict([query, document])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add padding\n",
    "query[:,5:] = np.zeros(5,)\n",
    "document[:,6:] = np.zeros(6,)\n",
    "y = model.predict([query, document])\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interactions import SemanticInteractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG created tokenizer disk4_5_RegexTokenizer\n",
      "False False\n",
      "[LOAD FROM CACHE] Load embedding matrix from /backup/IR/embedding_wiki_disk4_5_RegexTokenizer\n"
     ]
    }
   ],
   "source": [
    "from nir.embeddings import FastText\n",
    "from nir.tokenizers import Regex\n",
    "\n",
    "cache_folder = \"/backup/IR\"\n",
    "prefix_name = \"disk4_5\"\n",
    "\n",
    "# load tokenizer\n",
    "tk = Regex.load_from_json(cache_folder=cache_folder, prefix_name=prefix_name)\n",
    "\n",
    "# load embedding matrix\n",
    "ft = FastText.maybe_load(cache_folder = cache_folder,\n",
    "                         prefix_name = prefix_name,\n",
    "                         path = \"/backup/pre-trained_embeddings/fasttext/wiki.en.bin\",\n",
    "                         tokenizer = tk)\n",
    "\n",
    "emb_matrix = ft.embedding_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EMBEDDING MATRIX SHAPE] (228107, 300)\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "semantic_interactions (Semantic (None, 8, 4, 3)      600         input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 600\n",
      "Trainable params: 600\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "K.clear_session()\n",
    "\n",
    "input_query = tf.keras.layers.Input((8,), dtype=\"int32\")\n",
    "input_sentence = tf.keras.layers.Input((4,), dtype=\"int32\")\n",
    "\n",
    "semantic_interaction = SemanticInteractions(emb_matrix)\n",
    "\n",
    "_out = semantic_interaction([input_query, input_sentence])\n",
    "\n",
    "model = tf.keras.models.Model(inputs=[input_query, input_sentence], outputs=_out)\n",
    "model.summary()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = np.random.randint(0,100000,(1, 8))\n",
    "document = np.random.randint(0,100000,(1, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.19258466 0.25187984 0.22666241 0.28524923]\n",
      " [0.24372493 0.11448298 0.21717232 0.29039758]\n",
      " [0.16095555 0.25080484 0.12638587 0.08130907]\n",
      " [0.11486951 0.19863784 0.13232115 0.18147907]\n",
      " [0.18183693 0.23730841 0.19377872 0.199918  ]\n",
      " [0.1356947  0.0835322  0.083666   0.15122163]\n",
      " [0.07151814 0.19953083 0.07166837 0.23351286]\n",
      " [0.01318797 0.15260708 0.22389746 0.11909546]]\n",
      "[[ 0.05864156  0.05864156  0.05864156  0.05864156]\n",
      " [-0.05139646 -0.05139646 -0.05139646 -0.05139646]\n",
      " [-0.07237688 -0.07237688 -0.07237688 -0.07237688]\n",
      " [-0.11823501 -0.11823501 -0.11823501 -0.11823501]\n",
      " [-0.01284604 -0.01284604 -0.01284604 -0.01284604]\n",
      " [-0.16275871 -0.16275871 -0.16275871 -0.16275871]\n",
      " [ 0.0248914   0.0248914   0.0248914   0.0248914 ]\n",
      " [ 0.05576241  0.05576241  0.05576241  0.05576241]]\n",
      "[[-0.00682486 -0.0156595   0.01011591 -0.03786472]\n",
      " [-0.00682486 -0.0156595   0.01011591 -0.03786472]\n",
      " [-0.00682486 -0.0156595   0.01011591 -0.03786472]\n",
      " [-0.00682486 -0.0156595   0.01011591 -0.03786472]\n",
      " [-0.00682486 -0.0156595   0.01011591 -0.03786472]\n",
      " [-0.00682486 -0.0156595   0.01011591 -0.03786472]\n",
      " [-0.00682486 -0.0156595   0.01011591 -0.03786472]\n",
      " [-0.00682486 -0.0156595   0.01011591 -0.03786472]]\n"
     ]
    }
   ],
   "source": [
    "y = model.predict([query, document])\n",
    "print(y[0,:,:,0])\n",
    "print(y[0,:,:,1])\n",
    "print(y[0,:,:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.19258466  0.25187984  0.          0.        ]\n",
      " [ 0.24372493  0.11448298 -0.         -0.        ]\n",
      " [ 0.16095555  0.25080484 -0.         -0.        ]\n",
      " [ 0.11486951  0.19863784  0.          0.        ]\n",
      " [ 0.         -0.          0.          0.        ]\n",
      " [ 0.         -0.          0.          0.        ]\n",
      " [ 0.         -0.          0.          0.        ]\n",
      " [ 0.         -0.          0.          0.        ]]\n",
      "[[ 0.05864156  0.05864156  0.          0.        ]\n",
      " [-0.05139646 -0.05139646 -0.         -0.        ]\n",
      " [-0.07237688 -0.07237688 -0.         -0.        ]\n",
      " [-0.11823501 -0.11823501 -0.         -0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "[[-0.00682486 -0.0156595   0.          0.        ]\n",
      " [-0.00682486 -0.0156595   0.          0.        ]\n",
      " [-0.00682486 -0.0156595   0.          0.        ]\n",
      " [-0.00682486 -0.0156595   0.          0.        ]\n",
      " [-0.         -0.          0.          0.        ]\n",
      " [-0.         -0.          0.          0.        ]\n",
      " [-0.         -0.          0.          0.        ]\n",
      " [-0.         -0.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# add padding\n",
    "query[:,4:] = np.zeros(4,)\n",
    "document[:,2:] = np.zeros(2,)\n",
    "y = model.predict([query, document])\n",
    "print(y[0,:,:,0])\n",
    "print(y[0,:,:,1])\n",
    "print(y[0,:,:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow2Wnir",
   "language": "python",
   "name": "tensor2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
